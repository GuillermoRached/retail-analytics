{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d25555-d9ee-4329-a86c-e1f3f49f1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00313431-4ae2-4fe1-9e34-72529f6473e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('400_transactions.csv')\n",
    "products_df = pd.read_csv('400_products.csv')\n",
    "households_df = pd.read_csv('400_households.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45839733-f3ab-4b67-9b51-02f9587bc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df['PURCHASE_'] = pd.to_datetime(transactions_df['PURCHASE_'], format='%m/%d/%Y')\n",
    "\n",
    "last_purchase_dates = transactions_df.groupby('HSHD_NUM')['PURCHASE_'].max()\n",
    "\n",
    "dataset_end_date = transactions_df['PURCHASE_'].max()\n",
    "churn_threshold = pd.Timedelta(days=90)  # 3 months\n",
    "\n",
    "churned_customers = (dataset_end_date - last_purchase_dates) > churn_threshold\n",
    "churn_status = pd.DataFrame({\n",
    "    'HSHD_NUM': churned_customers.index,\n",
    "    'is_churned': churned_customers.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df0f07-c85f-4517-ba45-5b887f05952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_customer_features(transactions_df, households_df):\n",
    "    \"\"\"\n",
    "    Calculate features for each customer that might indicate likelihood to churn.\n",
    "    Now updated with correct column names from the dataset.\n",
    "    \"\"\"\n",
    "    customer_patterns = transactions_df.groupby('HSHD_NUM').agg({\n",
    "        'BASKET_NUM': 'nunique',\n",
    "        'SPEND': ['mean', 'sum', 'std'],\n",
    "        'PURCHASE_': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    customer_patterns.columns = [\n",
    "        'HSHD_NUM', 'total_trips', 'avg_spend', \n",
    "        'total_spend', 'spend_std', 'first_purchase', 'last_purchase'\n",
    "    ]\n",
    "    \n",
    "    customer_patterns['customer_lifetime'] = (\n",
    "        customer_patterns['last_purchase'] - \n",
    "        customer_patterns['first_purchase']\n",
    "    ).dt.days\n",
    "    \n",
    "    customer_patterns['avg_time_between_trips'] = (\n",
    "        customer_patterns['customer_lifetime'] / \n",
    "        customer_patterns['total_trips']\n",
    "    )\n",
    "    \n",
    "    customer_features = customer_patterns.merge(\n",
    "        households_df, \n",
    "        on='HSHD_NUM',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    customer_features = customer_features.merge(\n",
    "        churn_status,\n",
    "        on='HSHD_NUM',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return customer_features\n",
    "\n",
    "customer_features = calculate_customer_features(transactions_df, households_df)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='is_churned', y='avg_spend', data=customer_features)\n",
    "plt.title('Average Spend by Churn Status')\n",
    "plt.xlabel('Churned')\n",
    "plt.ylabel('Average Spend per Trip')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x='is_churned', y='avg_time_between_trips', data=customer_features)\n",
    "plt.title('Shopping Frequency by Churn Status')\n",
    "plt.xlabel('Churned')\n",
    "plt.ylabel('Average Days Between Trips')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "churn_by_income = customer_features.groupby('INCOME_RANGE')['is_churned'].mean()\n",
    "churn_by_income.plot(kind='bar')\n",
    "plt.title('Churn Rate by Income Range')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Churn Rate')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "churn_by_size = customer_features.groupby('HH_SIZE')['is_churned'].mean()\n",
    "churn_by_size.plot(kind='bar')\n",
    "plt.title('Churn Rate by Household Size')\n",
    "plt.xlabel('Household Size')\n",
    "plt.ylabel('Churn Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f061d07-2968-46ba-8ba5-7f8a736095b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values in our features:\")\n",
    "print(feature_df.isnull().sum())\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "numeric_features = [\n",
    "    'total_trips', 'avg_spend', 'total_spend', 'spend_std',\n",
    "    'customer_lifetime', 'avg_time_between_trips', 'HH_SIZE', 'CHILDREN'\n",
    "]\n",
    "\n",
    "categorical_features = ['INCOME_RANGE', 'L', 'AGE_RANGE', 'MARITAL', 'HOMEOWNER']\n",
    "\n",
    "numeric_df = customer_features[numeric_features].copy()\n",
    "categorical_df = customer_features[categorical_features].copy()\n",
    "\n",
    "numeric_df = pd.DataFrame(\n",
    "    numeric_imputer.fit_transform(numeric_df),\n",
    "    columns=numeric_features,\n",
    "    index=numeric_df.index\n",
    ")\n",
    "\n",
    "categorical_df = pd.DataFrame(\n",
    "    categorical_imputer.fit_transform(categorical_df),\n",
    "    columns=categorical_features,\n",
    "    index=categorical_df.index\n",
    ")\n",
    "\n",
    "categorical_dummies = pd.get_dummies(categorical_df)\n",
    "\n",
    "feature_df = pd.concat([numeric_df, categorical_dummies], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_df[numeric_features] = scaler.fit_transform(feature_df[numeric_features])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_df,\n",
    "    customer_features['is_churned'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nChurn Prediction Model Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_df.columns,\n",
    "    'importance': abs(model.coef_[0])\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
    "plt.title('Top 10 Features for Predicting Customer Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ddb8bf-16ba-49fc-bbf0-81ee0a8ea4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_features['churn_probability'] = model.predict_proba(feature_df)[:, 1]\n",
    "\n",
    "customer_features['risk_segment'] = pd.qcut(\n",
    "    customer_features['churn_probability'],\n",
    "    q=4,\n",
    "    labels=['Low Risk', 'Medium-Low Risk', 'Medium-High Risk', 'High Risk']\n",
    ")\n",
    "\n",
    "print(\"\\nCharacteristics of High-Risk Customers:\")\n",
    "high_risk = customer_features[customer_features['risk_segment'] == 'High Risk']\n",
    "print(\"\\nAverage Metrics for High-Risk Customers:\")\n",
    "print(high_risk[['avg_spend', 'total_trips', 'avg_time_between_trips']].mean())\n",
    "\n",
    "def generate_retention_recommendations(customer_features):\n",
    "    \"\"\"\n",
    "    Generate targeted retention strategies based on analysis results.\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    if customer_features['avg_spend'].mean() < customer_features['avg_spend'].median():\n",
    "        recommendations.append(\n",
    "            \"Implement targeted promotions for high-risk customers based on their purchase history\"\n",
    "        )\n",
    "    \n",
    "    if customer_features['avg_time_between_trips'].mean() > 14:\n",
    "        recommendations.append(\n",
    "            \"Develop an early warning system for customers showing decreased shopping frequency\"\n",
    "        )\n",
    "    \n",
    "    loyalty_impact = customer_features.groupby('L')['is_churned'].mean()\n",
    "    if 'Y' in loyalty_impact and 'N' in loyalty_impact:\n",
    "        if loyalty_impact['Y'] < loyalty_impact['N']:\n",
    "            recommendations.append(\n",
    "                \"Enhance loyalty program benefits and actively recruit non-members\"\n",
    "            )\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "print(\"\\nRecommended Retention Strategies:\")\n",
    "for rec in generate_retention_recommendations(customer_features):\n",
    "    print(f\"- {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216e381-dd0d-4ece-96f3-4f92f27e87fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
